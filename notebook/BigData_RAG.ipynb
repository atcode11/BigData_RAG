{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1X52TWxOfd3xNPbU1j6a-eyhCjl0LX4rI","timestamp":1714850366515}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["This notebook takes in multiple PDF files from a folder and can answer questions based on multiple files"],"metadata":{"id":"TuFDll-UDPcy"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"DPJneDSAtEKx"},"outputs":[],"source":["!pip install -qq langchain_community\n","!pip install -qq tiktoken\n","!pip install -qq langchain-openai\n","!pip install -qq chromadb\n","!pip install -qq langchain\n","!pip install -qq pypdf"]},{"cell_type":"code","source":["from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain_community.document_loaders import PyPDFLoader\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.runnables import RunnablePassthrough\n","from langchain_community.vectorstores import Chroma\n","from langchain.prompts import ChatPromptTemplate\n","from langchain_openai import OpenAIEmbeddings\n","from langchain_openai import ChatOpenAI\n","from langchain.load import dumps, loads\n","from operator import itemgetter\n","from getpass import getpass\n","import os"],"metadata":{"id":"lfQ3pRsOtFPY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from IPython.display import display, Markdown\n","def md(t):\n","  display(Markdown(t))"],"metadata":{"id":"N1nNubLRtGkZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"hnTxcodQtIWh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","folder_path = '/content/drive/My Drive/RAG'"],"metadata":{"id":"FC_vWXO9tTWI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["list(os.listdir(folder_path))"],"metadata":{"id":"kaZpgd97tlcP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pdf_files = [file_name for file_name in list(os.listdir(folder_path)) if file_name.endswith('.pdf')]"],"metadata":{"id":"CxfjdEdIto6u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pdf_contents = {}\n","for pdf in pdf_files:\n","  pdf_path = os.path.join(folder_path,pdf)\n","  loader = PyPDFLoader(pdf_path)\n","  pdf_contents[pdf]=loader.load()"],"metadata":{"id":"ZffiRrYOuwSe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n","    chunk_size=300,\n","    chunk_overlap=50)"],"metadata":{"id":"5Q0TreSDuwcA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_splits = []\n","for doc_content in pdf_contents.values():\n","  split = text_splitter.split_documents(doc_content)\n","  all_splits.extend(split)"],"metadata":{"id":"mJspLFyRupXF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.environ['OPENAI_API_KEY'] = getpass(\"Enter your OpenAI API Key...\")"],"metadata":{"id":"65MA5CGJyWLJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"API Key Set:\", \"OPENAI_API_KEY\" in os.environ)  # This should print True if set\n"],"metadata":{"id":"wgd-10HWyvXR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["api_key = os.environ.get('OPENAI_API_KEY')"],"metadata":{"id":"qARtRIBm0cU0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vectorstore = Chroma.from_documents(documents=all_splits,\n","                                    embedding=OpenAIEmbeddings())"],"metadata":{"id":"La6nH-JpxaSc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})"],"metadata":{"id":"EVM0Rv7R4kOr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"],"metadata":{"id":"QqiFS9qF69Ai"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["template = \"\"\"Answer the question based only on the following context:\n","{context}.\n","Also provide the source of the answer with page number from the document.\n","Question: {question}\n","\"\"\"\n","\n","prompt = ChatPromptTemplate.from_template(template)\n","prompt"],"metadata":{"id":"HiE9SPrO6_ej"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_query_response(question):\n","    docs = retriever.invoke(question)\n","    for i in range(len(docs)):\n","        print(f'Relevant Chunk Number- {i}')\n","        page_content = docs[i].page_content\n","        print(\"Page Content:\")\n","        md(page_content)\n","        page_number = docs[i].metadata['page']\n","        source = docs[i].metadata['source']\n","        print('-------------')\n","        print(\"Page Number: \",page_number)\n","        print('-------------')\n","        print(\"Source: \",source)\n","        print('-----------------')"],"metadata":{"id":"MIa-7Utk7P5f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# how are you answering questions - based on contextual info which is given by the retriever\n","rag_chain = (\n","    {\"context\": retriever, \"question\": RunnablePassthrough()}\n","    | prompt\n","    | llm\n","    | StrOutputParser()\n",")"],"metadata":{"id":"toIE11p97Da1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["question = \"\"\"Bigtable maintains data in lexicographic order by row keys. The row range\n","(or tablet) for a table is dynamically partitioned, and the tablet is the unit\n","of distribution and load balancing. Is this true of false\"\"\""],"metadata":{"id":"o1MJ2FSa7Fbs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response = rag_chain.invoke(question)\n","md(response)"],"metadata":{"id":"vSdkrrr17HXA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["question = \"\"\"Bigtable supports cross-row transactions to perform atomic read-modify- write sequences on data stored under several row keys.\"\"\""],"metadata":{"id":"HhA7mUSK7I3h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response = rag_chain.invoke(question)\n","md(response)"],"metadata":{"id":"QP-g9trT7VEJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["question = \"\"\"In Bigtable, every read and write of data under a single row key is atomic (regardless of number of different columns being read or written in the\n","row).\"\"\"\n","\n","response = rag_chain.invoke(question)\n","md(response)"],"metadata":{"id":"B3GLt3GO7V8b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"RAUYitMb7xEt"}},{"cell_type":"code","source":["question = \"\"\"Bigtable prefer a bigger number of distinct column families in a table. True or Flase\"\"\"\n","\n","response = rag_chain.invoke(question)\n","md(response)"],"metadata":{"id":"04NwVka_7shc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["question = \"\"\"Bigtable is a column-family NoSQL using GFS store and a column family\n","must be created before data can be stored. True or Flase\"\"\"\n","\n","response = rag_chain.invoke(question)\n","md(response)"],"metadata":{"id":"DAmJO9as7u4H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["question = \"\"\"Bigtable uses garbage collection based on timestamps to either only the\n","last n versions of a cell be kept or only new-enough versions be kept, and different versions of a cell are stored in increasing timestamp order (so that the least recent versions can be read first). True or Flase\"\"\"\n","\n","response = rag_chain.invoke(question)\n","md(response)"],"metadata":{"id":"1G4WNOvT75SJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["question = \"\"\"GFSduplicatesdatatonreplicas.\n","a) How to fully utilize each machine’s network bandwidth? b) How to avoid network bottlenecks?\n","c) How to minimize the latency to push through all data? \"\"\"\n","\n","response = rag_chain.invoke(question)\n","md(response)"],"metadata":{"id":"hiw6vwDm7_iL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["question = \"\"\"The Google File System uses a master to store 64-bytes metadata about each file, each file is divided into 64-MB chunks. If the master node has 8GB main memory,\n","a) How many total chunks can be supported? What is the total size of the GFS\n","system?\n","b) If there are n files and the average size of files is m-MB, and assume there\n","is no aggregation of small files, how many total space is wasted due to internal fragmentation? \"\"\"\n","\n","response = rag_chain.invoke(question)\n","md(response)"],"metadata":{"id":"W29NwFXC8HjV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["question ='''Jim Gray’s five minute rule (1986) says “pages referenced every five minutes should be memory resident.” It is purely an economic issue: when it is cheaper to keep a record in main memory rather than access it on disk. Then any 1KB record accessed more frequently than every 300 seconds (or 5 minutes) should live in main memory. Jim Gray’s five byte rule says “Spend five bytes of main memory to save one instruction per second”: when does it make sense to use more memory to save CPU power, or conversely save some memory at the expense of CPU cycles. A Tandem disk cost $15K can deliver 15 accesses/sec, and extra CPU and channel cost for supporting a disk access are $0.5K/access/sec. A megabyte of Tandem memory cost $5K, and instruction cost is $25K/mips.\n","a) Please show how you derive this five minute rule?\n","b) Please show how you derive this five byte rule?\n","c) For smaller (or larger) records, are you expecting the time should be longer\n","or shorter than 5 minutes? Please show how you derive this five byte rule? For smaller (or larger) records, are you prefer to trade memory for CPU time or not?'''\n","\n","response = rag_chain.invoke(question)\n","md(response)"],"metadata":{"id":"4eRGpiQX8RHA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["question = \"\"\"Suppose we have a table urls: (url, category, pagerank). The following is a simple SQL query that finds, for each sufficiently large category, the average pagerank of high-pagerank urls in that category. Please write a PigLatin program that do the same thing.\n","SELECT category, AVG(pagerank)\n","FROM urls WHERE pagerank > 0.2\n","GROUP BY category HAVING COUNT(*) > 106\"\"\"\n","\n","response = rag_chain.invoke(question)\n","md(response)"],"metadata":{"id":"yDezzQ5s8ci7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["question = \"\"\"  A distributed system (e.g., RAMCloud) with n servers (each has m GB main memory and a disk with maximum transfer\n","rate of t MB/sec) connected by c Gbps links (i.e., each node has maximum c Gbps network speed). The system uses log-structured memory\n","system with one master data in main memory and r backup copies in disks at different servers. If a server crashed, a recovery server will load data from backup copies parallelly.\n","a) If m = 64, t = 100, c = 10, and r = 3, how long the recovery server can\n","restore the 64 MB master data?\n","b) If we change r = 1000, how long the recovery server can restore the 64 MB\n","master data?\n","c) Generally, less than 2 seconds recovery is fast enough to constitute\n","“continuous availability” for most applications.\n","If we partition the master data into r chunks and store them on different servers and use r recovery\n","servers to restore them in parallel, what is the minimum integer value of r can we reduce restore time less than 2 second?\n","(E.g., this is the fast recovery scheme used in RAMCloud)\"\"\"\n","\n","response = rag_chain.invoke(question)\n","md(response)"],"metadata":{"id":"yapiK4q28i96"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["question = \"\"\"  For the input via a socket as below:\n","       pencil\n","       book\n","       key\n","       pencil\n","       book\n","       key\n","       Cup\n","       book\n","       pencil\n","       paper\n","       cup\n","       book\n","       pencil\n","       paper\n","       book\n","What is the output of the following code?\n","from pyspark.sql import SparkSession from pyspark.sql.functions import * from pyspark.sql.types import *\n","# Streaming via socket\n","spark = SparkSession.builder.appName(\"streamCsv\").getOrCreate() rawdata = spark.readStream.format(\"socket\").option(\n","\"host\", \"localhost\").option(\"port\",9999).option(\n","\"includeTimestamp\", True).load()\n","query = rawdata.select((rawdata.value).alias(\"product\"),\n","(rawdata.timestamp).alias(\"time\")).groupBy(window(\"time\", \"1\n","minutes\"), \"product\").count().sort(desc(\"window\")) result = query.writeStream.format(\"console\").outputMode(\n","\"complete\").start().awaitTermination() result.stop()\n","Please give the output.result. Print the result\"\"\"\n","\n","response = rag_chain.invoke(question)\n","md(response)"],"metadata":{"id":"IojZ3a6i8u_j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["question = \"\"\"Given the stream data via a file under a directory “test” as below:id,firstname,age,profession,city,salary 100,Babita,27,Lawyer,Riverside,1558.0\n","101,Zsa Zsa,39,Musician,Male,5667.0 102,Vonny,48,Plice Officer,Bahia Blanca,7612.0 103,Ermengarde,24,Teacher,Porto Alegre,2451.0 104,Karina,51,Software Developer,Amritsar,3522.0 105,Felice,36,Doctor,Montreal,9874.0 106,Elsie,55,Police Officer,City of San Marino,2231.0 107,Kaia,36,Police Officer,Gaza,2263.0 108,Glynnis,43,Designer,Hamburg,6983.0 109,Jany,28,Lawyer,Belize City,8769.0\n","Given the following partial pyspark code, please replace “pass” to working code to make it working, i.e., output the result as the table below:\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import *\n","from pyspark.sql.types import * # The schema\n","schema1 = StructType([\n","pass\n","])\n","# read files from test directory into a spark dataframe customer = spark.readStream.format(\"csv\").schema(schema1)\\ .option(\"header\", True).option(\"maxFilesPerTrigger\", 1)\\ .load(r\"test \")\n","# generate spark dataframe with sorted average salaries with counts\n","# for each profession\n","average_salaries = pass\n","# output stream to stdout and start streaming\n","query = pass\"\"\"\n","\n","response = rag_chain.invoke(question)\n","md(response)"],"metadata":{"id":"hlV7Knns89oh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["question = \"\"\"   Given the pyspark partial code below (with output in comments), please replace “pass” with working code to make it working.\n","from pyspark import *\n","sc = SparkContext.getOrCreate()\n","sc.addPyFile(\"/Library/Frameworks/Python.framework/Versions/3.7/l ib/python3.7/site-packages/pyspark/jars/graphframes-0.8.2- spark3.1-s_2.12.jar\")\n","from pyspark.sql import *\n","from graphframes import * vertices = spark.createDataFrame(\n","[\n","('1', 'Carter', 'Derrick', 50), ('2', 'May', 'Derrick', 26), ('3', 'Mills', 'Jeff', 80), ('4', 'Hood', 'Robert', 65), ('5', 'Banks', 'Mike', 93), ('98', 'Berg', 'Tim', 28), ('99', 'Page', 'Allan', 16)\n","], ['id', 'name', 'firstname', 'age'] )\n","edges = spark.createDataFrame( [\n","('1', '2', 'friend'), ('2', '1', 'friend'), ('3', '1', 'friend'), ('1', '3', 'friend'), ('2', '3', 'follows'), ('3', '4', 'friend'), ('4', '3', 'friend'), ('5', '3', 'friend'), ('3', '5', 'friend'), ('4', '5', 'follows'), ('98', '99', 'friend'), ('99', '98', 'friend')\n","], ['src', 'dst', 'type'] )\n","g = GraphFrame(vertices, edges)\n","g.edges.show()\n","\n","copy = edges\n","from pyspark.sql.functions import udf\n","# merge directed relationships into undirected ones @udf(\"string\")\n","def to_undir(src, dst):\n","pass\n","copy.withColumn('undir', to_undir(copy.src, copy.dst))\\\n",".filter('undir ==\n","\n","g.edges.filter('type == \"friend\"') sc.setCheckpointDir('graphframes_cps') g.find(\"(a)-[e]->(b); (b)-[e2]->(a)\").show()\n","mutualFriends = pass\n","mutualFriends.filter('a.id == 2 and c.id == 3').show() \"\"\"\n","\n","response = rag_chain.invoke(question)\n","md(response)"],"metadata":{"id":"UGz2rOZf9YTQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ZabQdsMf9mXg"},"execution_count":null,"outputs":[]}]}